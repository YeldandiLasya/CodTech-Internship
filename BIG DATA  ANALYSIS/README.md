
# Big Data Analysis using PySpark | TASK-1

🎯 Objective
The goal of this task is to apply Big Data analytics techniques using PySpark on a real-world retail dataset consisting of over 400,000 transaction records, in order to:

- Clean and process customer transaction data
- Analyze product categories, customer segments, and sales performance
- Understand customer ratings, purchase behavior, and feedback patterns
- Demonstrate scalability and efficiency using PySpark for large datasets

## 📁 Dataset

- Source: [Retail Analysis Large Dataset (Kaggle)](https://www.kaggle.com/datasets/sahilprajapati143/retail-analysis-large-dataset)
- File Used: `new_retail_data.csv`
- Sample size: ~100,000+ records
- Fields: Customer info, Transaction details, Product categories, Amount, Ratings, Time, etc.

## 🚀 Tools & Technologies

- 🐍 Python
- 🔥 PySpark (Apache Spark for Python)
- 📊 Matplotlib & Seaborn (for visualizations)
- 🧠 Pandas (for plotting with Spark-converted DataFrames)

## 📈 Key Features / Analysis

The project performs the following analyses using PySpark:

1. **Total Revenue by Country**  
2. **Top-Selling Product Categories**
3. **Average Spend by Customer Segment**
4. **Monthly Sales Trend**
5. **Gender-based Spending Analysis**
6. **Ratings Distribution**
